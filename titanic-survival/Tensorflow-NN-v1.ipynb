{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "#Score 0.78468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Need doctring\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a placeholder for x\n",
    "    x = tf.placeholder(tf.float32, name='x')\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(tf.sigmoid(x), feed_dict = {x : z})\n",
    "    \n",
    "    return result\n",
    "\n",
    "def test_sigmoid():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(logits, labels):\n",
    "    \"\"\"\"\"\"\n",
    "    y = tf.placeholder(tf.float32, name='y')\n",
    "    z = tf.placeholder(tf.float32, name='z')\n",
    "    \n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z, labels=y)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        cost = sess.run(cost, feed_dict={z: logits, y: labels})\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training examples: 12\n",
      "shape of X_train: (891, 12)\n",
      "shape of Y_train: (891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan Cervin</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7538</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330972</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>Caldwell, Mr. Albert Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>Abrahim, Mrs. Joseph (Sophie Halaut Easu)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2657</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>Davies, Mr. John Samuel</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A/4 48871</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "5          897       3                    Svensson, Mr. Johan Cervin    male   \n",
       "6          898       3                          Connolly, Miss. Kate  female   \n",
       "7          899       2                  Caldwell, Mr. Albert Francis    male   \n",
       "8          900       3     Abrahim, Mrs. Joseph (Sophie Halaut Easu)  female   \n",
       "9          901       3                       Davies, Mr. John Samuel    male   \n",
       "\n",
       "    Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0     330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0     363272   7.0000   NaN        S  \n",
       "2  62.0      0      0     240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0     315154   8.6625   NaN        S  \n",
       "4  22.0      1      1    3101298  12.2875   NaN        S  \n",
       "5  14.0      0      0       7538   9.2250   NaN        S  \n",
       "6  30.0      0      0     330972   7.6292   NaN        Q  \n",
       "7  26.0      1      1     248738  29.0000   NaN        S  \n",
       "8  18.0      0      0       2657   7.2292   NaN        C  \n",
       "9  21.0      2      0  A/4 48871  24.1500   NaN        S  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import train and test data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "X_train = train_df\n",
    "Y_train = train_df\n",
    "# X_train = train_df.drop(\"Survived\", axis=1)\n",
    "# Y_train = train_df[\"Survived\"]\n",
    "# X_train.shape\n",
    "\n",
    "X_test = test_df\n",
    "test_passenger_id= test_df[\"PassengerId\"]\n",
    "\n",
    "\n",
    "# determine data shape and configuration\n",
    "print('no. of training examples: ' + str(X_train.shape[1]))\n",
    "print('shape of X_train: ' + str(X_train.shape))\n",
    "print('shape of Y_train: ' + str(Y_train.shape))\n",
    "\n",
    "X_train.head(10)\n",
    "X_test.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper functions to preprocess\n",
    "def drop_cols(dframe, cols):\n",
    "    return data.drop(cols, axis=1)\n",
    "\n",
    "cols_to_drop = ['PassengerId','Name', 'Ticket', 'Cabin','Embarked']\n",
    "X_train = X_train.drop(cols_to_drop, axis=1)\n",
    "X_test = X_test.drop(cols_to_drop, axis=1)\n",
    "\n",
    "# find columns that contain NaN values if any\n",
    "X_train.columns[X_train.isna().any()].tolist()\n",
    "X_train.columns[X_train.isnull().any()].tolist()\n",
    "# find number of NaN values for each column\n",
    "X_train.isna().sum()\n",
    "\n",
    "# X_train['Fare'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare\n",
       "0         0       3    1  22.0      1      0   7.2500\n",
       "1         1       1    0  38.0      1      0  71.2833\n",
       "2         1       3    0  26.0      0      0   7.9250\n",
       "3         1       1    0  35.0      1      0  53.1000\n",
       "4         0       3    1  35.0      0      0   8.0500\n",
       "5         0       3    1   NaN      0      0   8.4583\n",
       "6         0       1    1  54.0      0      0  51.8625\n",
       "7         0       3    1   2.0      3      1  21.0750\n",
       "8         1       3    0  27.0      0      2  11.1333\n",
       "9         1       2    0  14.0      1      0  30.0708"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some sklearn preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_label(data, col):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data[col].unique().tolist())\n",
    "    data[col]=le.transform(data[col]) \n",
    "    return data\n",
    "    \n",
    "# X_train['Sex'].unique().tolist()\n",
    "\n",
    "X_train = encode_label(X_train, 'Sex')\n",
    "X_test = encode_label(X_test, 'Sex')\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(tf.float32, [n_x, None], name='X')\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None], name='Y')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    False\n",
       "Pclass      False\n",
       "Sex         False\n",
       "Age         False\n",
       "SibSp       False\n",
       "Parch       False\n",
       "Fare        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "def nan_padding(data, columns):\n",
    "    for column in columns:\n",
    "        imputer=Imputer()\n",
    "        data[column]=imputer.fit_transform(data[column].values.reshape(-1,1))\n",
    "    return data\n",
    "\n",
    "\n",
    "nan_columns = [\"Age\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "X_train = nan_padding(X_train, nan_columns)\n",
    "X_test = nan_padding(X_test, nan_columns)\n",
    "\n",
    "def dummy_data(data, columns):\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
    "        data = data.drop(column, axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "X_train['Fare'] = X_train['Fare'].fillna(X_train['Fare'].median())\n",
    "X_test['Fare'] = X_test['Fare'].fillna(X_test['Fare'].median())\n",
    "\n",
    "# dummy_columns = [\"Pclass\"]\n",
    "# X_train=dummy_data(X_train, dummy_columns)\n",
    "# X_test=dummy_data(X_test, dummy_columns)\n",
    "X_train.head(10)\n",
    "\n",
    "X_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for dataset in [X_train, X_test]:\n",
    "#     # Mapping Embarked\n",
    "# #     dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "#     # Mapping Fare\n",
    "#     dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "#     dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "#     dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "#     dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "#     dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "#     # Mapping Age\n",
    "#     dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "#     dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "#     dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "#     dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "#     dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x:(712, 6)\n",
      "train_y:(712, 1)\n",
      "train_y content:[[1]\n",
      " [1]\n",
      " [0]]\n",
      "valid_x:(179, 6)\n",
      "valid_y:(179, 1)\n"
     ]
    }
   ],
   "source": [
    "# def initialize_params():\n",
    "#     \"\"\" \"\"\"\n",
    "#     W1 = tf.get_variable('W1', )\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "def normalize_age(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    data[\"Age\"] = scaler.fit_transform(data[\"Age\"].values.reshape(-1,1))\n",
    "    return data\n",
    "X_train = normalize_age(X_train)\n",
    "X_test = normalize_age(X_test)\n",
    "X_train.head()\n",
    "\n",
    "# train_x, valid_x, train_y, valid_y = train_test_split(X_train, Y_train)\n",
    "\n",
    "def split_valid_test_data(data, fraction=(1 - 0.8)):\n",
    "    data_y = data[\"Survived\"]\n",
    "    lb = LabelBinarizer()\n",
    "    data_y = lb.fit_transform(data_y)\n",
    "\n",
    "    data_x = data.drop([\"Survived\"], axis=1)\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data_x, data_y, test_size=fraction)\n",
    "\n",
    "    return train_x.values, train_y, valid_x, valid_y\n",
    "train_x, train_y, valid_x, valid_y = split_valid_test_data(X_train)\n",
    "\n",
    "\n",
    "print(\"train_x:{}\".format(train_x.shape))\n",
    "print(\"train_y:{}\".format(train_y.shape))\n",
    "print(\"train_y content:{}\".format(train_y[:3]))\n",
    "\n",
    "print(\"valid_x:{}\".format(valid_x.shape))\n",
    "print(\"valid_y:{}\".format(valid_y.shape))\n",
    "\n",
    "\n",
    "\n",
    "# train_x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "def build_neural_network(hidden_units=10):\n",
    "    tf.reset_default_graph()\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, train_x.shape[1]])\n",
    "    labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    is_training=tf.Variable(True,dtype=tf.bool)\n",
    "    \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    fc = tf.layers.dense(inputs, hidden_units, activation=None,kernel_initializer=initializer)\n",
    "    fc=tf.layers.batch_normalization(fc, training=is_training)\n",
    "    fc=tf.nn.relu(fc)\n",
    "    \n",
    "    logits = tf.layers.dense(fc, 1, activation=None)\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    predicted = tf.nn.sigmoid(logits)\n",
    "    correct_pred = tf.equal(tf.round(predicted), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Export the nodes \n",
    "    export_nodes = ['inputs', 'labels', 'learning_rate','is_training', 'logits',\n",
    "                    'cost', 'optimizer', 'predicted', 'accuracy']\n",
    "    Graph = namedtuple('Graph', export_nodes)\n",
    "    local_dict = locals()\n",
    "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
    "\n",
    "    return graph\n",
    "\n",
    "model = build_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data_x,data_y,batch_size=32):\n",
    "    batch_n=len(data_x)//batch_size\n",
    "    for i in range(batch_n):\n",
    "        batch_x=data_x[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y=data_y[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        yield batch_x,batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/200 Train Loss: 0.4299 Train Acc: 0.8048\n",
      "Epoch: 23/200 Validation Loss: 0.4473 Validation Acc: 0.8380\n",
      "Epoch: 46/200 Train Loss: 0.4079 Train Acc: 0.8230\n",
      "Epoch: 46/200 Validation Loss: 0.3479 Validation Acc: 0.8771\n",
      "Epoch: 69/200 Train Loss: 0.4015 Train Acc: 0.8301\n",
      "Epoch: 69/200 Validation Loss: 0.3319 Validation Acc: 0.8715\n",
      "Epoch: 91/200 Train Loss: 0.3964 Train Acc: 0.8287\n",
      "Epoch: 91/200 Validation Loss: 0.3322 Validation Acc: 0.8827\n",
      "Epoch: 114/200 Train Loss: 0.3919 Train Acc: 0.8357\n",
      "Epoch: 114/200 Validation Loss: 0.3265 Validation Acc: 0.8827\n",
      "Epoch: 137/200 Train Loss: 0.3869 Train Acc: 0.8385\n",
      "Epoch: 137/200 Validation Loss: 0.3272 Validation Acc: 0.8547\n",
      "Epoch: 160/200 Train Loss: 0.3804 Train Acc: 0.8343\n",
      "Epoch: 160/200 Validation Loss: 0.3224 Validation Acc: 0.8883\n",
      "Epoch: 182/200 Train Loss: 0.3768 Train Acc: 0.8371\n",
      "Epoch: 182/200 Validation Loss: 0.3191 Validation Acc: 0.8939\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "train_collect = 50\n",
    "train_print=train_collect*10\n",
    "\n",
    "learning_rate_value = 0.001\n",
    "batch_size=32\n",
    "\n",
    "\n",
    "x_collect = []\n",
    "train_loss_collect = []\n",
    "train_acc_collect = []\n",
    "valid_loss_collect = []\n",
    "valid_acc_collect = []\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration=0\n",
    "    for e in range(epochs):\n",
    "        for batch_x,batch_y in get_batch(train_x,train_y,batch_size):\n",
    "            iteration+=1\n",
    "            feed = {model.inputs: train_x,\n",
    "                    model.labels: train_y,\n",
    "                    model.learning_rate: learning_rate_value,\n",
    "                    model.is_training:True\n",
    "                   }\n",
    "\n",
    "            train_loss, _, train_acc = sess.run([model.cost, model.optimizer, model.accuracy], feed_dict=feed)\n",
    "            \n",
    "            if iteration % train_collect == 0:\n",
    "                x_collect.append(e)\n",
    "                train_loss_collect.append(train_loss)\n",
    "                train_acc_collect.append(train_acc)\n",
    "\n",
    "                if iteration % train_print==0:\n",
    "                     print(\"Epoch: {}/{}\".format(e + 1, epochs),\n",
    "                      \"Train Loss: {:.4f}\".format(train_loss),\n",
    "                      \"Train Acc: {:.4f}\".format(train_acc))\n",
    "                        \n",
    "                feed = {model.inputs: valid_x,\n",
    "                        model.labels: valid_y,\n",
    "                        model.is_training:False\n",
    "                       }\n",
    "                val_loss, val_acc = sess.run([model.cost, model.accuracy], feed_dict=feed)\n",
    "                valid_loss_collect.append(val_loss)\n",
    "                valid_acc_collect.append(val_acc)\n",
    "                \n",
    "                if iteration % train_print==0:\n",
    "                    print(\"Epoch: {}/{}\".format(e + 1, epochs),\n",
    "                      \"Validation Loss: {:.4f}\".format(val_loss),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "                \n",
    "\n",
    "    saver.save(sess, \"./titanic.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./titanic.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.09059235],\n",
       "       [ 0.81261176],\n",
       "       [ 0.07943363],\n",
       "       [ 0.08803612],\n",
       "       [ 0.45018101],\n",
       "       [ 0.19406626],\n",
       "       [ 0.60541189],\n",
       "       [ 0.31591845],\n",
       "       [ 0.61372489],\n",
       "       [ 0.08567898]], dtype=float32)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=build_neural_network()\n",
    "restorer=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    restorer.restore(sess,\"./titanic.ckpt\")\n",
    "    feed={\n",
    "        model.inputs:X_test,\n",
    "        model.is_training:False\n",
    "    }\n",
    "    test_predict=sess.run(model.predicted,feed_dict=feed)\n",
    "    \n",
    "test_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer=Binarizer(0.5)\n",
    "test_predict_result=binarizer.fit_transform(test_predict)\n",
    "test_predict_result=test_predict_result.astype(np.int32)\n",
    "test_predict_result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0\n",
       "5          897         0\n",
       "6          898         1\n",
       "7          899         0\n",
       "8          900         1\n",
       "9          901         0"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passenger_id=test_passenger_id.copy()\n",
    "evaluation=passenger_id.to_frame()\n",
    "evaluation[\"Survived\"]=test_predict_result\n",
    "evaluation[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.to_csv(\"nn_submission_v1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
